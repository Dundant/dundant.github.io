---
layout:     post
title:      python 处理数据的哪些坑
subtitle:   Pitfalls in Data Analysis Using Python
date:       2020-02-02
author:     Dundant
header-img: img/007-python-data-preprocess.png
catalog:    true
tags:
    math python data_analysis
---
> 本文作为自己处理一些数据的经验之谈，当然也是基于我自身痛苦经历的分享。写此文既是为了给读者一个能够辨识规避个中错误的方法，姑且称之为一份轻指南，另外写此文也是为了让我以后不再反相同的错误，共同取得进步，与诸君共勉。

## 起因
文中所提及的案例均是源自2019年我的两份课程作业的，此处不会提及这两份作业的具体内容。

## 单文件表格处理
如果只是一个文件，一个很格式很好的一维表，那么问题的关键就在与，pandas 读取大文件时，通常会因为内存不足而死机。比如一个１G大小的文件，对于一个8G内存的家用机就会过载的。不知道为什么，pandas 读取表格文件之后的 dataframe 会占用超过文件本身的大量内存。

解决这个问题的办法是：利用 pandas 的分快读取文件的功能，即把文件分成一个个 chunk，并产生一个个的 dataframe。暂时还不清除这种做法的缺点。

当然还有另外一个办法就是，利用 vaex 库。vaex 利用了 hdf5　格式，Python 使用这个库能够在家用机上读取超大型表格，而且运算速度很快，不会一般情况下，都是不会有死机的问题的。与一般的 dataframe 的用法不尽相同。

当然 vaex 的安装可能会存在某些问题， vaex 的官方文档推荐在　virtualenv 虚拟环境安装使用，而尽量不要在系统范围内直接安装。

既是大型文件的读取难题可以解决了。其他问题还包括：

**空值**。有些模型如果不去掉空值，就会报错。方法有两种：fillna 和　dropna，就如同英文名一样，这份别代表的是填空值和去空值。填空值的方法有两种，分别是用前一天或者后一天的值填空。

**重复行**。如果不认真处理重复行，重复行在某些情况下是会产生一些很难发现的错误的。通常在 sql 数据库中，index 或者 id 是不可以重复的。在 dataframe 中 row index 也是不可以重复的。但是一般在读取文件表格的时候，我们并不会使用表格中原本就有的　column index 作为　index 或者 id，也即是主键。那么这样的处理虽然会带来一些好处，例如在不需要了解表格全貌的时候，就可以读取 dataframe，不过问题就在于，这样就可能产生一些重复行；而在另外一些更狡猾的情况下，重复行的产生就变得更为平常了。就比如，在将多个 dataframe 纵向(也即 axis=0)组装的时候，通常我们会选择　ignore_index=True，这就极容易产生重复行的问题了。

好在应对办法也很简单，

至于重复行会引起的问题，除了会引起模型的结果不准确以外。另外的问题就是**在求笛卡尔集的时候，也即 merge 这个函数，会产生大量重复行，乃至于重复多次会致使内存爆掉**。

**二维表**。讨论这个问题之前，必须明晰一下什么叫二维表，什么叫一维表。

二维表与一维表的区别就在于：一维表的每一行都是一个观测值，或者说是一个单独的对象，显著特征就是每一列都是被观测对象的一个维度的属性。而二维表则不服从这一个规律，二维表的每一个格子才是一个观测值，那么这样的话，不适合计量模型分析。

解决办法也有。

## 多个表格文件的处理
比如一个数据按如下的方式组织：

也即，其中的每一个文件代表了一个小的表格，而文件夹则表示了一种分类－－这通常是按时间。

由于表格分散在多个文件中，而且在多数情况下，不能够直接阅读表格，所以是没有办法产生一个对数据的全貌的。在这种情况下，数据的说明，就显得极为重要。不过由于数据的整理方可能在形成数据中发生人工错误，或者由于数据本身源于某种自动化作业，本身缺少人工审查，因此数据也有可能会产生不可预料的错误，又或者由于技术变革或者社会投入增加、乃至法律国家标准的改变导致的随着时间的发展，数据本身会产生变化－－例如新的空气检测标准使得原有的空气污染指数(API)被现行的空气质量指数(AQI)，当然这些都不重要，最好的是直接提供空气中各项污染物的浓度，而不是一个意义不明的空气质量指数。当然新的空气检测标准真正的用处是增加的污染物的观测项目数。

又比如，大气气象检测站点，不可能在一开始就全部建立，而是必须一个一个站点的建立，这就导致了，后来建立的站点，没有之前的数据。对于研究无用。

除了时间维度上的前后不一致，还有一个问题可能是，某些表格文件实际上是完全错误的。比如数据都是用网页爬虫爬取，那么就有可能有几个文件就不是格式化的文本，而是html错误页面。所以在写代码的时候，就必须注意到这一点，也即是　try except 结构。

值得注意的是，再使用try except的时候，尽量不要使用不带 Exception　的　except　语句。因为这样做可能会让程序异常，产生不符合的结果，如果能知道结果不是良好的，那也不是问题。关键就在于如果结果不符合预期，同时又发现不了。那就是个大问题了。所以尽量不要使用不带 Exception 的　except　语句。也就是说，所有可预期的的异常情况都需要在代码中体现出来。异常是无限的，同时也是呈现显著单峰分布的，所以必须要使用有限的异常情况对应处理绝大多数的异常。

当然，多表格的处理，同时也会出现上述单表格文件的问题。

## 总结
数据处理可能出现的问题：
 - 空值
 - 重复行，尤其是拼接 dataframe 的过程中
 - 二维表到一维表的转换
 - 多表格拼接的字段，异常处理
