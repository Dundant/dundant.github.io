---
layout:     post
title:      python 处理数据的哪些坑
subtitle:   Pitfalls in Data Analysis Using Python
date:       2019-02-02
author:     Dundant
header-img: https://ae01.alicdn.com/kf/H34a237fbbd7d4f9e8f8dffa925de77511.jpg
catalog: true
tags:
    math 数学 概率 金融 finance
---
| 本文作为自己处理一些数据的经验之谈，当然也是基于我自身痛苦经历的分享。写此文既是为了给读者一个能够辨识规避个中错误的方法，姑且称之为一份轻指南，另外写此文也是为了让我以后不再反相同的错误，共同取得进步，与诸君共勉。

## 起因
文中所提及的案例均是源自2019年我的两份课程作业的，此处不会提及这两份作业的具体内容。

## 单文件表格处理
如果只是一个文件，一个很格式很好的一维表，那么问题的关键就在与，pandas 读取大文件时，通常会因为内存不足而死机。比如一个１G大小的文件，对于一个8G内存的家用机就会过载的。不知道为什么，pandas 读取表格文件之后的 dataframe 会占用超过文件本身的大量内存。

解决这个问题的办法是：利用 pandas 的分快读取文件的功能，即把文件分成一个个 chunk，并产生一个个的 dataframe。暂时还不清除这种做法的缺点。

当然还有另外一个办法就是，利用 vaex 库。vaex 利用了 hdf5　格式，Python 使用这个库能够在家用机上读取超大型表格，而且运算速度很快，不会一般情况下，都是不会有死机的问题的。与一般的 dataframe 的用法不尽相同。

当然 vaex 的安装可能会存在某些问题， vaex 的官方文档推荐在　virtualenv 虚拟环境安装使用，而尽量不要在系统范围内直接安装。

既是大型文件的读取难题可以解决了。其他问题还包括：

**空值**。有些模型如果不去掉空值，就会报错。方法有两种：fillna 和　dropna，就如同英文名一样，这份别代表的是填空值和去空值。填空值的方法有两种，分别是用前一天或者后一天的值填空。

**重复行**。如果不认真处理重复行，重复行在某些情况下是会产生一些很难发现的错误的。通常在 sql 数据库中，index 或者 id 是不可以重复的。在 dataframe 中 row index 也是不可以重复的。但是一般在读取文件表格的时候，我们并不会使用表格中原本就有的　column index 作为　index 或者 id，也即是主键。那么这样的处理虽然会带来一些好处，例如在不需要了解表格全貌的时候，就可以读取 dataframe，不过问题就在于，这样就可能产生一些重复行；而在另外一些更狡猾的情况下，重复行的产生就变得更为平常了。就比如，在将多个 dataframe 纵向(也即 axis=0)组装的时候，通常我们会选择　ignore_index=True，这就极容易产生重复行的问题了。

**二维表**。讨论这个问题之前，必须明晰一下什么叫二维表，什么叫一维表。

二维表与一维表的区别就在于：一维表的每一行都是一个观测值，或者说是一个单独的对象，显著特征就是每一列都是被观测对象的一个维度的属性。而二维表则不服从这一个规律，二维表的每一个格子才是一个观测值，那么这样的话，

好在应对办法也很简单，

说道重复行会引起的问题，除了会引起模型的结果不准确以外。另外的问题就是**在求笛卡尔集的时候，也即 merge 这个函数，会产生大量重复行，乃至于重复多次会致使内存爆掉**。

## 多个表格文件的处理
比如一个数据按如下的方式组织：

也即，其中的每一个文件代表了一个小的表格，而文件夹则表示了一种分类－－这通常是按时间。

由于表格分散在
